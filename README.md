# Cell-counting / ì…€ ì¹´ìš´íŒ…

Utilities and models for automated cell counting with the RetinaNet
(ResNet-50 FPN) detector that powers the production notebooks.

RetinaNet(ResNet-50 FPN) ê²€ì¶œê¸°ë¥¼ í™œìš©í•´ ìë™ìœ¼ë¡œ ì„¸í¬ë¥¼ ì„¸ëŠ” ë° í•„ìš”í•œ
ìœ í‹¸ë¦¬í‹°ì™€ ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤.

<img src="docs/assets/cell_counting_result.png" alt="Annotated cell counting example" width="400">

<p align="center">
  <a href="#"><img src="https://img.shields.io/badge/python-3.9%2B-blue.svg?style=flat-square"></a>
  <a href="#"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square"></a>
</p>

## TODO

### UI interface _(assigned to S.Yeon)_

- [x] Provide an entry point to choose between a live microscope feed and an
      imported image for cell counting.
- [x] Integrate direct interpretation from a connected microscope adapter.
- [x] Enable real-time region selection while viewing the microscope feed.
- [x] Invoke the counting model and present a fixed annotated image along with
      the predicted count (no live overlay required).
- [x] Allow users to add or remove bounding boxes and update the cell count
      interactively.
- [x] Support exporting the analysed image, mirroring the workflow for imported
      images.

## ğŸ“‘ Table of Contents / ëª©ì°¨
- [TODO](#todo)
- [Project Overview](#project-overview)
- [Features](#features)
- [Quickstart](#quickstart)
- [Python Usage](#python-usage)
- [Streamlit App](#streamlit-app)
- [Additional Resources](#additional-resources)
- [Evaluation](#evaluation)
- [Examples](#examples)

## Project overview / í”„ë¡œì íŠ¸ ê°œìš”

This repository packages everything needed to detect and count cells in
hemocytometer images. It bundles trained RetinaNet weights, Python helpers for
single or batch inference, and a Streamlit app for interactive experimentation.
The implementation mirrors the original `hepatocytometer.ipynb` workflow while
remaining easy to install and extend.

ì´ ì €ì¥ì†ŒëŠ” í˜ˆêµ¬ê³„ìˆ˜ê¸° ì´ë¯¸ì§€ë¥¼ íƒì§€í•˜ê³  ì„¸ê¸° ìœ„í•œ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼
í¬í•¨í•©ë‹ˆë‹¤. í•™ìŠµëœ RetinaNet ê°€ì¤‘ì¹˜, ë‹¨ì¼Â·ë°°ì¹˜ ì¶”ë¡ ì„ ìœ„í•œ Python í—¬í¼,
ê·¸ë¦¬ê³  ëŒ€í™”í˜• ì‹¤í—˜ìš© Streamlit ì•±ì„ í•¨ê»˜ ì œê³µí•˜ë©°, ì›ë³¸
`hepatocytometer.ipynb` ì›Œí¬í”Œë¡œë¥¼ ë°˜ì˜í•˜ë©´ì„œë„ ì„¤ì¹˜ì™€ í™•ì¥ì´ ì‰½ë„ë¡
ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## Features / íŠ¹ì§•

- RetinaNet (ResNet-50 FPN) wrapper with convenient weight-loading helpers.  
  ê°€ì¤‘ì¹˜ ë¡œë”©ì´ ê°„í¸í•œ RetinaNet(ResNet-50 FPN) ë˜í¼ ì œê³µ
- `load_model` and `count_cells` APIs for scripted inference on files or Pillow
  images.  
  íŒŒì¼ ë˜ëŠ” Pillow ì´ë¯¸ì§€ë¥¼ ëŒ€ìƒìœ¼ë¡œ ìŠ¤í¬ë¦½íŠ¸í˜• ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ëŠ”
  `load_model`, `count_cells` API
- Batch prediction utilities that export CSV summaries and annotated overlays.  
  CSV ìš”ì•½ê³¼ ì£¼ì„ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ë‚´ë³´ë‚´ëŠ” ë°°ì¹˜ ì˜ˆì¸¡ ìœ í‹¸ë¦¬í‹°
- Streamlit demo that visualises predictions directly in the browser.  
  ë¸Œë¼ìš°ì €ì—ì„œ ì˜ˆì¸¡ì„ ì‹œê°í™”í•˜ëŠ” Streamlit ë°ëª¨

## Quickstart / ë¹ ë¥¸ ì‹œì‘

1. Clone the repository and move into the project directory.  
   ì €ì¥ì†Œë¥¼ í´ë¡ í•˜ê³  í”„ë¡œì íŠ¸ ë””ë ‰í„°ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤.

   ```bash
   git clone https://github.com/<your-org>/Cell-counting.git
   cd Cell-counting
   ```

2. (Optional) Create and activate a virtual environment.  
   (ì„ íƒ ì‚¬í•­) ê°€ìƒ í™˜ê²½ì„ ìƒì„±í•˜ê³  í™œì„±í™”í•©ë‹ˆë‹¤.
3. Install runtime dependencies.  
   ëŸ°íƒ€ì„ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.

   ```bash
   pip install -r requirements.txt
   ```

4. Download the pretrained detector weights and place them in
   `results/models/best.pt` (or provide a custom path when loading the model).  
   ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ `results/models/best.pt`ì— ë‘ê±°ë‚˜ ëª¨ë¸ ë¡œë”© ì‹œ
   ì›í•˜ëŠ” ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
5. Run the Streamlit demo or use the Python API to confirm the setup.  
   Streamlit ë°ëª¨ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ Python APIë¡œ êµ¬ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤.

## Python usage / Python ì‚¬ìš©ë²•

```python
from cell_counting import count_cells, load_model

model = load_model(
    weights_path="results/models/best.pt",
    device="cuda:0",  # or "cpu"
    image_size=640,
)

count, boxes, annotated = count_cells(
    "docs/assets/seq0432_jpg.rf.f16687b29f969b08fdc2900f51b3e5d3.jpg",
    weights_path="results/models/best.pt",
    blank_image="path/to/blank_reference.jpg",  # optional
    return_image=True,
    draw=True,
)
annotated.save("prediction.jpg")
print(f"Detected {count} cells across {len(boxes)} boxes")
```

Tips / íŒ:

- Provide a blank reference frame to remove background artefacts when
  necessary.  
  í•„ìš”í•˜ë‹¤ë©´ ë¹ˆ ê¸°ì¤€ í”„ë ˆì„ì„ ì œê³µí•´ ë°°ê²½ ì•„í‹°íŒ©íŠ¸ë¥¼ ì œê±°í•˜ì„¸ìš”.
- Adjust `conf`, `nms_iou`, `size_min`, and `size_max` to tailor detections to
  your imagery.  
  `conf`, `nms_iou`, `size_min`, `size_max` ê°’ì„ ì¡°ì •í•´ ì´ë¯¸ì§€ íŠ¹ì„±ì— ë§ëŠ”
  íƒì§€ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- Use `cell_counting.inference.predict_folder(...)` for batch processing with
  CSV summaries and annotated overlays.  
  CSV ìš”ì•½ê³¼ ì£¼ì„ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ìƒì„±í•˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬ì—ëŠ”
  `cell_counting.inference.predict_folder(...)`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

## Streamlit app / Streamlit ì•±

After installing dependencies and downloading the trained weights, launch the
interactive demo from the project root:

```bash
streamlit run streamlit_app.py
```

Use the sidebar to select checkpoints, upload microscope imagery, adjust
thresholds, toggle blank-frame subtraction, and download annotated results
without writing code. The interface also lets you switch between live capture
and local files, crop a region of interest before running inference, tweak the
predicted bounding boxes, and immediately recalculate the resulting cell count.

ì‚¬ì´ë“œë°”ì—ì„œ ì²´í¬í¬ì¸íŠ¸ ì„ íƒ, í˜„ë¯¸ê²½ ì´ë¯¸ì§€ ì—…ë¡œë“œ, ì„ê³„ê°’ ì¡°ì •, ë¹ˆ í”„ë ˆì„
ë³´ì • í† ê¸€, ì£¼ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œê¹Œì§€ ì½”ë“œë¥¼ ì‘ì„±í•˜ì§€ ì•Šê³  ì§„í–‰í•  ìˆ˜
ìˆìŠµë‹ˆë‹¤.

## Additional resources / ì¶”ê°€ ìë£Œ

- `hepatocytometer.ipynb` &mdash; original exploratory notebook with the training
  and evaluation workflow.
- `docs/` &mdash; documentation assets, including sample images referenced in this
  README.
- `results/` &mdash; suggested directory layout for storing trained models and
  experiment outputs.

## Evaluation / í‰ê°€

Validation results bundled with the repository show that the detector predicts
counts very close to the ground truth. Across three validation frames, the
model recorded a mean absolute error of 1.33 cells (median 1, maximum 2). In
total it predicted 18 cells against 16 labelled cells. Per-image details are
available in `results/report_val.csv`.

ì €ì¥ì†Œì— í¬í•¨ëœ ê²€ì¦ ê²°ê³¼ì— ë”°ë¥´ë©´ ëª¨ë¸ì€ ì •ë‹µì— ê·¼ì ‘í•œ ì…€ ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ë©°,
ì„¸ ê°œì˜ ê²€ì¦ í”„ë ˆì„ì—ì„œ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ 1.33ê°œ(ì¤‘ì•™ê°’ 1, ìµœëŒ€ 2)ë¥¼
ê¸°ë¡í–ˆìŠµë‹ˆë‹¤. ì´ 16ê°œì˜ ë¼ë²¨ ì…€ì— ëŒ€í•´ 18ê°œë¥¼ ì˜ˆì¸¡í–ˆìœ¼ë©°, ì´ë¯¸ì§€ë³„ ìƒì„¸
ë‚´ì—­ì€ `results/report_val.csv`ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Model architecture diagram / ëª¨ë¸ êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨

Render the RetinaNet overview diagram (matching `cell_counting/model.py`) with:

`cell_counting/model.py`ì™€ ì¼ì¹˜í•˜ëŠ” RetinaNet ê°œìš” ë‹¤ì´ì–´ê·¸ë¨ì€ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ
ë Œë”ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
python docs/scripts/render_model_diagram.py --compile
```

The TikZ source is saved to `docs/assets/retinanet_architecture.tex`; when
LaTeX is available, the script also produces a PDF.

TikZ ì†ŒìŠ¤ëŠ” `docs/assets/retinanet_architecture.tex`ì— ì €ì¥ë˜ë©°, LaTeXì´ ì„¤ì¹˜ëœ
í™˜ê²½ì—ì„œëŠ” PDFë„ ìƒì„±ë©ë‹ˆë‹¤.

Refer to the [tests](tests/) folder for smoke tests that validate the package
installation and inference utilities.

## Examples / ì˜ˆì‹œ

The example assets live in `docs/assets/` as conventional JPG and PNG files so
you can inspect them directly or reuse them in your own experiments. The input
frame below matches the microscope crop supplied for this task and the
accompanying output shows the resulting overlay. The helper script
`docs/scripts/generate_examples.py` (which falls back to a lightweight
threshold-based segmentation when PyTorch is unavailable) regenerates both
artifacts from the source imagery and keeps the repository reproducible.

ì˜ˆì œ ìì‚°ì€ `docs/assets/` í´ë”ì— JPG/PNG í˜•íƒœë¡œ í¬í•¨ë˜ì–´ ìˆì–´ ë°”ë¡œ í™•ì¸í•˜ê±°ë‚˜
ì‹¤í—˜ì— ì¬ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ ì…ë ¥ í”„ë ˆì„ì€ ì œê³µëœ í˜„ë¯¸ê²½ í¬ë¡­ê³¼ ë™ì¼í•˜ë©°,
ì˜¤ë¥¸ìª½ ê²°ê³¼ëŠ” ìƒì„±ëœ ì˜¤ë²„ë ˆì´ë¥¼ ë³´ì—¬ ì¤ë‹ˆë‹¤.
PyTorchê°€ ì—†ëŠ” í™˜ê²½ì—ì„œëŠ” ê²½ëŸ‰í™”ëœ ì„ê³„ê°’ ë¶„í• ë¡œ ëŒ€ì²´í•˜ëŠ”
`docs/scripts/generate_examples.py` ìŠ¤í¬ë¦½íŠ¸ê°€ ë‘ ì•„í‹°íŒ©íŠ¸ë¥¼ ì¬ìƒì„±í•´ ë¬¸ì„œì˜
ì¬í˜„ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.

| Sample hemocytometer input | Annotated output |
| --- | --- |
| ![Sample input](docs/assets/seq0432_jpg.rf.f16687b29f969b08fdc2900f51b3e5d3.jpg) | ![Annotated output](docs/assets/cell_counting_result.png) |

The repository inference helpers (`cell_counting.count_cells` or
`cell_counting.inference.predict_image`) will recreate the overlay when PyTorch
is available. In environments where the heavy dependencies cannot be installed,
the regeneration script resorts to intensity-based segmentation to draw
bounding boxes so that the documentation remains illustrative.

